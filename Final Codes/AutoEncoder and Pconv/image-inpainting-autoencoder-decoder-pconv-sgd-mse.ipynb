{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7KlcVNbe29Ez"
   },
   "source": [
    "# Setups, Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:24.161396Z",
     "iopub.status.busy": "2022-05-06T04:47:24.160479Z",
     "iopub.status.idle": "2022-05-06T04:47:31.558837Z",
     "shell.execute_reply": "2022-05-06T04:47:31.557165Z",
     "shell.execute_reply.started": "2022-05-06T04:47:24.161350Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:31.560632Z",
     "iopub.status.busy": "2022-05-06T04:47:31.560208Z",
     "iopub.status.idle": "2022-05-06T04:47:48.126674Z",
     "shell.execute_reply": "2022-05-06T04:47:48.125597Z",
     "shell.execute_reply.started": "2022-05-06T04:47:31.560586Z"
    },
    "id": "R31qb_nV3DsD",
    "outputId": "b214ac76-dcec-489b-f0ba-7e56bc58316d"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb -q\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:48.129345Z",
     "iopub.status.busy": "2022-05-06T04:47:48.128581Z",
     "iopub.status.idle": "2022-05-06T04:47:48.143817Z",
     "shell.execute_reply": "2022-05-06T04:47:48.142811Z",
     "shell.execute_reply.started": "2022-05-06T04:47:48.129282Z"
    },
    "id": "y85SvPWS37yf",
    "outputId": "129f158d-5c1f-48f5-928e-71ae5d3ff8ee"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:48.146720Z",
     "iopub.status.busy": "2022-05-06T04:47:48.145242Z",
     "iopub.status.idle": "2022-05-06T04:47:48.415066Z",
     "shell.execute_reply": "2022-05-06T04:47:48.414064Z",
     "shell.execute_reply.started": "2022-05-06T04:47:48.146581Z"
    },
    "id": "sd8ViDQz4-az"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKgylid25AZf"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:48.419418Z",
     "iopub.status.busy": "2022-05-06T04:47:48.418797Z",
     "iopub.status.idle": "2022-05-06T04:47:56.742463Z",
     "shell.execute_reply": "2022-05-06T04:47:56.741198Z",
     "shell.execute_reply.started": "2022-05-06T04:47:48.419372Z"
    },
    "id": "7QXxse9j5QgT",
    "outputId": "93d331ca-d1ee-4490-ef68-0d6531ed0f52"
   },
   "outputs": [],
   "source": [
    "## Cifar 100 Dataset\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUXXvOEv5IGo"
   },
   "source": [
    "#### Visualization of Cifar 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:56.744795Z",
     "iopub.status.busy": "2022-05-06T04:47:56.744423Z",
     "iopub.status.idle": "2022-05-06T04:47:58.597458Z",
     "shell.execute_reply": "2022-05-06T04:47:58.596406Z",
     "shell.execute_reply.started": "2022-05-06T04:47:56.744743Z"
    },
    "id": "-MlpaK7o7qWN",
    "outputId": "03f3f35c-7a40-4f1f-8ad3-b455fe9e2852"
   },
   "outputs": [],
   "source": [
    "## Get first 32 images as samples\n",
    "sample_images = x_train[:12]\n",
    "sample_labels = y_train[:12]\n",
    "\n",
    "fig = plt.figure(figsize=(16., 8.))\n",
    "grid = ImageGrid(fig, 111,\n",
    "                 nrows_ncols=(3,4 ),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, image, label in zip(grid, sample_images, sample_labels):\n",
    "  ax.imshow(image)\n",
    "  ax.set_title(label[0])\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_ZOEa8X4XBx"
   },
   "source": [
    "#### Data Generator with Patch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:58.599601Z",
     "iopub.status.busy": "2022-05-06T04:47:58.599195Z",
     "iopub.status.idle": "2022-05-06T04:47:58.619446Z",
     "shell.execute_reply": "2022-05-06T04:47:58.618106Z",
     "shell.execute_reply.started": "2022-05-06T04:47:58.599479Z"
    },
    "id": "kXeGgrfHmtHP"
   },
   "outputs": [],
   "source": [
    "## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\n",
    "class createAugment(keras.utils.Sequence):\n",
    "  'Generates data for Keras'\n",
    "  def __init__(self, X, y, batch_size=512, dim=(32, 32), n_channels=3, shuffle=True):\n",
    "      'Initialization'\n",
    "      self.batch_size = batch_size \n",
    "      self.X = X \n",
    "      self.y = y\n",
    "      self.dim = dim\n",
    "      self.n_channels = n_channels\n",
    "      self.shuffle = shuffle\n",
    "      \n",
    "      self.on_epoch_end()\n",
    "\n",
    "  def __len__(self):\n",
    "      'Denotes the number of batches per epoch'\n",
    "      return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Generate data\n",
    "      return self.__data_generation(indexes)\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "      'Updates indexes after each epoch'\n",
    "      self.indexes = np.arange(len(self.X))\n",
    "      if self.shuffle:\n",
    "          np.random.shuffle(self.indexes)\n",
    "\n",
    "  def __data_generation(self, idxs):\n",
    "    # X_batch is a matrix of masked images used as input\n",
    "    X_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Masked image\n",
    "    # y_batch is a matrix of original images used for computing error from reconstructed image\n",
    "    y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Original image\n",
    "\n",
    "    ## Iterate through random indexes\n",
    "    for i, idx in enumerate(idxs):\n",
    "      image_copy = self.X[idx].copy()\n",
    "  \n",
    "      ## Get mask associated to that image\n",
    "      masked_image = self.__createMask(image_copy)\n",
    "      \n",
    "      X_batch[i,] = masked_image/255\n",
    "      y_batch[i] = self.y[idx]/255\n",
    "      \n",
    "    return X_batch, y_batch\n",
    "\n",
    "  def __createMask(self, img):\n",
    "    ## Prepare masking matrix\n",
    "    mask = np.full((32,32,3), 255, np.uint8)\n",
    "    for _ in range(np.random.randint(1, 10)):\n",
    "      # Get random x locations to start line\n",
    "      x1, x2 = np.random.randint(1, 32), np.random.randint(1, 32)\n",
    "      # Get random y locations to start line\n",
    "      y1, y2 = np.random.randint(1, 32), np.random.randint(1, 32)\n",
    "      # Get random thickness of the line drawn\n",
    "      thickness = np.random.randint(2, 6)\n",
    "      # Draw black line on the white mask\n",
    "      cv2.line(mask,(x1,y1),(x2,y2),(1,1,1),thickness)\n",
    "\n",
    "    # Perforn bitwise and operation to mak the image\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:58.621706Z",
     "iopub.status.busy": "2022-05-06T04:47:58.621216Z",
     "iopub.status.idle": "2022-05-06T04:47:58.636033Z",
     "shell.execute_reply": "2022-05-06T04:47:58.635076Z",
     "shell.execute_reply.started": "2022-05-06T04:47:58.621658Z"
    },
    "id": "jdLSfboho0Sw"
   },
   "outputs": [],
   "source": [
    "## Prepare training and testing mask-image pair generator\n",
    "traingen = createAugment(x_train, x_train)\n",
    "testgen = createAugment(x_test, x_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:58.639366Z",
     "iopub.status.busy": "2022-05-06T04:47:58.638675Z",
     "iopub.status.idle": "2022-05-06T04:47:58.650077Z",
     "shell.execute_reply": "2022-05-06T04:47:58.648866Z",
     "shell.execute_reply.started": "2022-05-06T04:47:58.639320Z"
    }
   },
   "outputs": [],
   "source": [
    "len(traingen)*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:47:58.651868Z",
     "iopub.status.busy": "2022-05-06T04:47:58.651569Z",
     "iopub.status.idle": "2022-05-06T04:48:03.340365Z",
     "shell.execute_reply": "2022-05-06T04:48:03.339369Z",
     "shell.execute_reply.started": "2022-05-06T04:47:58.651834Z"
    },
    "id": "rXD1vfqisJKO",
    "outputId": "da9476fe-19d0-47b9-de33-ec3601fc6a39"
   },
   "outputs": [],
   "source": [
    "## Examples\n",
    "sample_idx = 90 ## Change this to see different batches\n",
    "\n",
    "sample_masks, sample_labels = traingen[sample_idx]\n",
    "sample_images = [None]*(len(sample_masks)+len(sample_labels))\n",
    "sample_images[::2] = sample_labels\n",
    "sample_images[1::2] = sample_masks\n",
    "\n",
    "fig = plt.figure(figsize=(16., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, image in zip(grid, sample_images):\n",
    "  ax.imshow(image)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZV1122baC4a"
   },
   "source": [
    "## Autoencoder-Decoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:48:03.342869Z",
     "iopub.status.busy": "2022-05-06T04:48:03.342310Z",
     "iopub.status.idle": "2022-05-06T04:48:03.350647Z",
     "shell.execute_reply": "2022-05-06T04:48:03.349276Z",
     "shell.execute_reply.started": "2022-05-06T04:48:03.342829Z"
    },
    "id": "f5aLz3OFgPkm"
   },
   "outputs": [],
   "source": [
    "## For more information into formulation: https://www.youtube.com/watch?v=AZr64OxshLo\n",
    "## Metric\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = keras.backend.flatten(y_true)\n",
    "    y_pred_f = keras.backend.flatten(y_pred)\n",
    "    intersection = keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection) / (keras.backend.sum(y_true_f + y_pred_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:48:03.352827Z",
     "iopub.status.busy": "2022-05-06T04:48:03.352465Z",
     "iopub.status.idle": "2022-05-06T04:48:03.362412Z",
     "shell.execute_reply": "2022-05-06T04:48:03.361184Z",
     "shell.execute_reply.started": "2022-05-06T04:48:03.352778Z"
    },
    "id": "a1QVmlTS-YxC"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:48:03.365388Z",
     "iopub.status.busy": "2022-05-06T04:48:03.364705Z",
     "iopub.status.idle": "2022-05-06T04:48:03.388785Z",
     "shell.execute_reply": "2022-05-06T04:48:03.387558Z",
     "shell.execute_reply.started": "2022-05-06T04:48:03.365339Z"
    },
    "id": "lPA7heLiZHY0"
   },
   "outputs": [],
   "source": [
    "class inpaintingModel:\n",
    "  '''\n",
    "  Build UNET like model for image inpaining task.\n",
    "  '''\n",
    "  def prepare_model(self, input_size=(32,32,3)):\n",
    "    inputs = keras.layers.Input(input_size)\n",
    "\n",
    "    conv1, pool1 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', inputs) \n",
    "    conv2, pool2 = self.__ConvBlock(64, (3,3), (2,2), 'relu', 'same', pool1)\n",
    "    conv3, pool3 = self.__ConvBlock(128, (3,3), (2,2), 'relu', 'same', pool2) \n",
    "    conv4, pool4 = self.__ConvBlock(256, (3,3), (2,2), 'relu', 'same', pool3) \n",
    "    \n",
    "    conv5, up6 = self.__UpConvBlock(512, 256, (3,3), (2,2), (2,2), 'relu', 'same', pool4, conv4)\n",
    "    conv6, up7 = self.__UpConvBlock(256, 128, (3,3), (2,2), (2,2), 'relu', 'same', up6, conv3)\n",
    "    conv7, up8 = self.__UpConvBlock(128, 64, (3,3), (2,2), (2,2), 'relu', 'same', up7, conv2)\n",
    "    conv8, up9 = self.__UpConvBlock(64, 32, (3,3), (2,2), (2,2), 'relu', 'same', up8, conv1)\n",
    "    \n",
    "    conv9 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', up9, False)\n",
    "    \n",
    "    outputs = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv9)\n",
    "\n",
    "    return keras.models.Model(inputs=[inputs], outputs=[outputs])  \n",
    "\n",
    "  def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n",
    "    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "    if pool_layer:\n",
    "      pool = keras.layers.MaxPooling2D(pool_size)(conv)\n",
    "      return conv, pool\n",
    "    else:\n",
    "      return conv\n",
    "\n",
    "  def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n",
    "    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "    conv = keras.layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "    up = keras.layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n",
    "    up = keras.layers.concatenate([up, shared_layer], axis=3)\n",
    "\n",
    "    return conv, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:50:12.393240Z",
     "iopub.status.busy": "2022-05-06T04:50:12.392928Z",
     "iopub.status.idle": "2022-05-06T04:50:13.061493Z",
     "shell.execute_reply": "2022-05-06T04:50:13.060422Z",
     "shell.execute_reply.started": "2022-05-06T04:50:12.393200Z"
    },
    "id": "lnMiuRBMbVP1",
    "outputId": "f2711917-8737-4ede-94ba-e7fd9beabadc"
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = inpaintingModel().prepare_model()\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=[dice_coef])\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=76, to_file='model_v1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d-0ydDC45lqp"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:50:22.075870Z",
     "iopub.status.busy": "2022-05-06T04:50:22.075244Z",
     "iopub.status.idle": "2022-05-06T04:50:33.102268Z",
     "shell.execute_reply": "2022-05-06T04:50:33.101100Z",
     "shell.execute_reply.started": "2022-05-06T04:50:22.075832Z"
    },
    "id": "i5SyVdBI83qB",
    "outputId": "8ec84c5d-c83e-48e9-834b-111f73b74fb8"
   },
   "outputs": [],
   "source": [
    "wandb.init(entity='kv1388', project=\"image-impainting-mse-sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:50:33.106568Z",
     "iopub.status.busy": "2022-05-06T04:50:33.106248Z",
     "iopub.status.idle": "2022-05-06T04:50:33.118658Z",
     "shell.execute_reply": "2022-05-06T04:50:33.117383Z",
     "shell.execute_reply.started": "2022-05-06T04:50:33.106525Z"
    },
    "id": "WDcXxpi3HW9d"
   },
   "outputs": [],
   "source": [
    "class PredictionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(PredictionLogger, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, logs, epoch):\n",
    "        sample_idx = 54\n",
    "        sample_images, sample_labels = testgen[sample_idx]  \n",
    "        \n",
    "        images = []\n",
    "        labels = []\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(512):\n",
    "            inpainted_image = self.model.predict(np.expand_dims(sample_images[i], axis=0))\n",
    "\n",
    "            images.append(sample_images[i])\n",
    "            labels.append(sample_labels[i])\n",
    "            predictions.append(inpainted_image.reshape(inpainted_image.shape[1:]))\n",
    "\n",
    "        wandb.log({\"images\": [wandb.Image(image)\n",
    "                              for image in images]})\n",
    "        wandb.log({\"labels\": [wandb.Image(label)\n",
    "                              for label in labels]})\n",
    "        wandb.log({\"predictions\": [wandb.Image(inpainted_image)\n",
    "                              for inpainted_image in predictions]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T04:50:33.122066Z",
     "iopub.status.busy": "2022-05-06T04:50:33.121144Z",
     "iopub.status.idle": "2022-05-06T06:11:14.353645Z",
     "shell.execute_reply": "2022-05-06T06:11:14.352092Z",
     "shell.execute_reply.started": "2022-05-06T04:50:33.122015Z"
    },
    "id": "-Fs2unJagj0h",
    "outputId": "790dd8d3-dd2a-4504-a31c-ae9ada2db5ec"
   },
   "outputs": [],
   "source": [
    "_ = model.fit(traingen, \n",
    "          validation_data=testgen, \n",
    "          epochs=50, \n",
    "          steps_per_epoch=len(traingen), \n",
    "          validation_steps=len(testgen),\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[WandbCallback(),\n",
    "                     PredictionLogger()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:11:14.361240Z",
     "iopub.status.busy": "2022-05-06T06:11:14.360865Z",
     "iopub.status.idle": "2022-05-06T06:11:24.348119Z",
     "shell.execute_reply": "2022-05-06T06:11:24.344606Z",
     "shell.execute_reply.started": "2022-05-06T06:11:14.361192Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./encoder_decoder_sgd_50epochs_512batch-mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOSNwA4fGVpI"
   },
   "source": [
    "# Testing on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T18:04:26.54798Z",
     "iopub.status.busy": "2022-05-05T18:04:26.547422Z",
     "iopub.status.idle": "2022-05-05T18:04:26.557628Z",
     "shell.execute_reply": "2022-05-05T18:04:26.556734Z",
     "shell.execute_reply.started": "2022-05-05T18:04:26.547941Z"
    }
   },
   "outputs": [],
   "source": [
    "ssim(sample_labels[i],impainted_image[0],channel_axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-05T19:05:13.161508Z",
     "iopub.status.busy": "2022-05-05T19:05:13.161215Z",
     "iopub.status.idle": "2022-05-05T19:05:13.168661Z",
     "shell.execute_reply": "2022-05-05T19:05:13.167796Z",
     "shell.execute_reply.started": "2022-05-05T19:05:13.161472Z"
    }
   },
   "outputs": [],
   "source": [
    "impainted_image[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:11:24.361083Z",
     "iopub.status.busy": "2022-05-06T06:11:24.360745Z",
     "iopub.status.idle": "2022-05-06T06:12:17.374483Z",
     "shell.execute_reply": "2022-05-06T06:12:17.373572Z",
     "shell.execute_reply.started": "2022-05-06T06:11:24.361039Z"
    },
    "id": "0LUFo2cJImyv",
    "outputId": "fcce067b-5b7c-4efe-bec0-965d1d035603"
   },
   "outputs": [],
   "source": [
    "## Examples\n",
    "# model.load('./encoder_decoder_sgd_50epochs_512batch')\n",
    "rows = 20\n",
    "sample_idx = 54\n",
    "sample_images, sample_labels = traingen[sample_idx]\n",
    "ssim_test=[]\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=3, figsize=(6, 2*rows))\n",
    "\n",
    "for i in range(20):\n",
    "    impainted_image = model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n",
    "    axs[i][0].imshow(sample_labels[i])\n",
    "    axs[i][1].imshow(sample_images[i])\n",
    "    axs[i][2].imshow(impainted_image[0])\n",
    "for i in range(len(sample_images)):\n",
    "    impainted_image = model.predict(sample_images[i].reshape((1,)+sample_images[i].shape))\n",
    "    ssim_test.append(ssim(sample_labels[i],impainted_image[0],channel_axis=2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:12:17.377748Z",
     "iopub.status.busy": "2022-05-06T06:12:17.375938Z",
     "iopub.status.idle": "2022-05-06T06:12:17.385895Z",
     "shell.execute_reply": "2022-05-06T06:12:17.385043Z",
     "shell.execute_reply.started": "2022-05-06T06:12:17.377691Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(ssim_test)/len(ssim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:12:17.388312Z",
     "iopub.status.busy": "2022-05-06T06:12:17.387726Z",
     "iopub.status.idle": "2022-05-06T06:12:23.042244Z",
     "shell.execute_reply": "2022-05-06T06:12:23.041438Z",
     "shell.execute_reply.started": "2022-05-06T06:12:17.388268Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly.\n",
    "class createAugment(keras.utils.Sequence):\n",
    "  'Generates data for Keras'\n",
    "  def __init__(self, X, y, batch_size=512, dim=(32, 32), n_channels=3, shuffle=True):\n",
    "      'Initialization'\n",
    "      self.batch_size = batch_size \n",
    "      self.X = X \n",
    "      self.y = y\n",
    "      self.dim = dim\n",
    "      self.n_channels = n_channels\n",
    "      self.shuffle = shuffle\n",
    "      \n",
    "      self.on_epoch_end()\n",
    "\n",
    "  def __len__(self):\n",
    "      'Denotes the number of batches per epoch'\n",
    "      return int(np.floor(len(self.X) / self.batch_size))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      'Generate one batch of data'\n",
    "      # Generate indexes of the batch\n",
    "      indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "      # Generate data\n",
    "      X_inputs, y_output = self.__data_generation(indexes)\n",
    "      return X_inputs, y_output\n",
    "\n",
    "  def on_epoch_end(self):\n",
    "      'Updates indexes after each epoch'\n",
    "      self.indexes = np.arange(len(self.X))\n",
    "      if self.shuffle:\n",
    "          np.random.shuffle(self.indexes)\n",
    "\n",
    "  def __data_generation(self, idxs):\n",
    "    # Masked_images is a matrix of masked images used as input\n",
    "    Masked_images = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Masked image\n",
    "    # Mask_batch is a matrix of binary masks used as input\n",
    "    Mask_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Binary Masks\n",
    "    # y_batch is a matrix of original images used for computing error from reconstructed image\n",
    "    y_batch = np.empty((self.batch_size, self.dim[0], self.dim[1], self.n_channels)) # Original image\n",
    "    \n",
    "\n",
    "    ## Iterate through random indexes\n",
    "    for i, idx in enumerate(idxs):\n",
    "      image_copy = self.X[idx].copy()\n",
    "  \n",
    "      ## Get mask associated to that image\n",
    "      masked_image, mask = self.__createMask(image_copy)\n",
    "      \n",
    "      Masked_images[i,] = masked_image/255\n",
    "      Mask_batch[i,] = mask/255\n",
    "      y_batch[i] = self.y[idx]/255\n",
    "\n",
    "    ## Return mask as well because partial convolution require the same.\n",
    "    return [Masked_images, Mask_batch], y_batch\n",
    "\n",
    "  def __createMask(self, img):\n",
    "    ## Prepare masking matrix\n",
    "    mask = np.full((32,32,3), 255, np.uint8) ## White background\n",
    "    for _ in range(np.random.randint(1, 10)):\n",
    "      # Get random x locations to start line\n",
    "      x1, x2 = np.random.randint(1, 32), np.random.randint(1, 32)\n",
    "      # Get random y locations to start line\n",
    "      y1, y2 = np.random.randint(1, 32), np.random.randint(1, 32)\n",
    "      # Get random thickness of the line drawn\n",
    "      thickness = np.random.randint(1, 3)\n",
    "      # Draw black line on the white mask\n",
    "      cv2.line(mask,(x1,y1),(x2,y2),(0,0,0),thickness)\n",
    "\n",
    "    ## Mask the image\n",
    "    masked_image = img.copy()\n",
    "    masked_image[mask==0] = 255\n",
    "\n",
    "    return masked_image, mask\n",
    "\n",
    "## Prepare training and testing mask-image pair generator\n",
    "traingen = createAugment(x_train, x_train)\n",
    "testgen = createAugment(x_test, x_test, shuffle=False)\n",
    "\n",
    "# Legend: Original Image | Mask generated | Masked Image\n",
    "\n",
    "## Examples\n",
    "sample_idx = 90 ## Change this to see different batches\n",
    "\n",
    "[masked_images, masks], sample_labels = traingen[sample_idx]\n",
    "sample_images = [None]*(len(masked_images)+len(masks)+len(sample_labels))\n",
    "sample_images[::3] = sample_labels\n",
    "# masks[]\n",
    "sample_images[1::3] = masks\n",
    "sample_images[2::3] = masked_images\n",
    "\n",
    "fig = plt.figure(figsize=(17., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 9),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.3,  # pad between axes in inch.\n",
    "                 )\n",
    "\n",
    "for ax, image in zip(grid, sample_images):\n",
    "  ax.imshow(image)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:12:23.046328Z",
     "iopub.status.busy": "2022-05-06T06:12:23.045890Z",
     "iopub.status.idle": "2022-05-06T06:12:23.082939Z",
     "shell.execute_reply": "2022-05-06T06:12:23.081562Z",
     "shell.execute_reply.started": "2022-05-06T06:12:23.046275Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "## Reference: https://github.com/MathiasGruber/PConv-Keras/blob/master/libs/pconv_layer.py\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import InputSpec\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "\n",
    "class PConv2D(Conv2D):\n",
    "    def __init__(self, *args, n_channels=3, mono=False, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.input_spec = [InputSpec(ndim=4), InputSpec(ndim=4)]\n",
    "\n",
    "    def build(self, input_shape):        \n",
    "        \"\"\"Adapted from original _Conv() layer of Keras        \n",
    "        param input_shape: list of dimensions for [img, mask]\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "            \n",
    "        if input_shape[0][channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs should be defined. Found `None`.')\n",
    "            \n",
    "        self.input_dim = input_shape[0][channel_axis]\n",
    "        \n",
    "        # Image kernel\n",
    "        kernel_shape = self.kernel_size + (self.input_dim, self.filters)\n",
    "        self.kernel = self.add_weight(shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      name='img_kernel',\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        # Mask kernel\n",
    "        self.kernel_mask = K.ones(shape=self.kernel_size + (self.input_dim, self.filters))\n",
    "\n",
    "        # Calculate padding size to achieve zero-padding\n",
    "        self.pconv_padding = (\n",
    "            (int((self.kernel_size[0]-1)/2), int((self.kernel_size[0]-1)/2)), \n",
    "            (int((self.kernel_size[0]-1)/2), int((self.kernel_size[0]-1)/2)), \n",
    "        )\n",
    "\n",
    "        # Window size - used for normalization\n",
    "        self.window_size = self.kernel_size[0] * self.kernel_size[1]\n",
    "        \n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.filters,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        '''\n",
    "        We will be using the Keras conv2d method, and essentially we have\n",
    "        to do here is multiply the mask with the input X, before we apply the\n",
    "        convolutions. For the mask itself, we apply convolutions with all weights\n",
    "        set to 1.\n",
    "        Subsequently, we clip mask values to between 0 and 1\n",
    "        ''' \n",
    "\n",
    "        # Both image and mask must be supplied\n",
    "        if type(inputs) is not list or len(inputs) != 2:\n",
    "            raise Exception('PartialConvolution2D must be called on a list of two tensors [img, mask]. Instead got: ' + str(inputs))\n",
    "\n",
    "        # Padding done explicitly so that padding becomes part of the masked partial convolution\n",
    "        images = K.spatial_2d_padding(inputs[0], self.pconv_padding, self.data_format)\n",
    "        masks = K.spatial_2d_padding(inputs[1], self.pconv_padding, self.data_format)\n",
    "\n",
    "        # Apply convolutions to mask\n",
    "        mask_output = K.conv2d(\n",
    "            masks, self.kernel_mask, \n",
    "            strides=self.strides,\n",
    "            padding='valid',\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate\n",
    "        )\n",
    "\n",
    "        # Apply convolutions to image\n",
    "        img_output = K.conv2d(\n",
    "            (images*masks), self.kernel, \n",
    "            strides=self.strides,\n",
    "            padding='valid',\n",
    "            data_format=self.data_format,\n",
    "            dilation_rate=self.dilation_rate\n",
    "        )        \n",
    "\n",
    "        # Calculate the mask ratio on each pixel in the output mask\n",
    "        mask_ratio = self.window_size / (mask_output + 1e-8)\n",
    "\n",
    "        # Clip output to be between 0 and 1\n",
    "        mask_output = K.clip(mask_output, 0, 1)\n",
    "\n",
    "        # Remove ratio values where there are holes\n",
    "        mask_ratio = mask_ratio * mask_output\n",
    "\n",
    "        # Normalize iamge output\n",
    "        img_output = img_output * mask_ratio\n",
    "\n",
    "        # Apply bias only to the image (if chosen to do so)\n",
    "        if self.use_bias:\n",
    "            img_output = K.bias_add(\n",
    "                img_output,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "        \n",
    "        # Apply activations on the image\n",
    "        if self.activation is not None:\n",
    "            img_output = self.activation(img_output)\n",
    "            \n",
    "        return [img_output, mask_output]\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_last':\n",
    "            space = input_shape[0][1:-1]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding='same',\n",
    "                    stride=self.strides[i],\n",
    "                    dilation=self.dilation_rate[i])\n",
    "                new_space.append(new_dim)\n",
    "            new_shape = (input_shape[0][0],) + tuple(new_space) + (self.filters,)\n",
    "            return [new_shape, new_shape]\n",
    "        if self.data_format == 'channels_first':\n",
    "            space = input_shape[2:]\n",
    "            new_space = []\n",
    "            for i in range(len(space)):\n",
    "                new_dim = conv_output_length(\n",
    "                    space[i],\n",
    "                    self.kernel_size[i],\n",
    "                    padding='same',\n",
    "                    stride=self.strides[i],\n",
    "                    dilation=self.dilation_rate[i])\n",
    "                new_space.append(new_dim)\n",
    "            new_shape = (input_shape[0], self.filters) + tuple(new_space)\n",
    "            return [new_shape, new_shape]\n",
    "\n",
    "## Reference: https://github.com/keras-team/keras/blob/7a39b6c62d43c25472b2c2476bd2a8983ae4f682/keras/utils/conv_utils.py#L85\n",
    "def conv_output_length(input_length, filter_size,\n",
    "                       padding, stride, dilation=1):\n",
    "    \"\"\"Determines output length of a convolution given input length.\n",
    "    # Arguments\n",
    "        input_length: integer.\n",
    "        filter_size: integer.\n",
    "        padding: one of `\"same\"`, `\"valid\"`, `\"full\"`.\n",
    "        stride: integer.\n",
    "        dilation: dilation rate, integer.\n",
    "    # Returns\n",
    "        The output length (integer).\n",
    "    \"\"\"\n",
    "    if input_length is None:\n",
    "        return None\n",
    "    assert padding in {'same', 'valid', 'full', 'causal'}\n",
    "    dilated_filter_size = (filter_size - 1) * dilation + 1\n",
    "    if padding == 'same':\n",
    "        output_length = input_length\n",
    "    elif padding == 'valid':\n",
    "        output_length = input_length - dilated_filter_size + 1\n",
    "    elif padding == 'causal':\n",
    "        output_length = input_length\n",
    "    elif padding == 'full':\n",
    "        output_length = input_length + dilated_filter_size - 1\n",
    "    return (output_length + stride - 1) // stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:12:23.085489Z",
     "iopub.status.busy": "2022-05-06T06:12:23.084938Z",
     "iopub.status.idle": "2022-05-06T06:12:23.109907Z",
     "shell.execute_reply": "2022-05-06T06:12:23.108510Z",
     "shell.execute_reply.started": "2022-05-06T06:12:23.085440Z"
    }
   },
   "outputs": [],
   "source": [
    "class InpaintingModel_2:\n",
    "  '''\n",
    "  Build UNET like model for image inpaining task.\n",
    "  '''\n",
    "  def prepare_model(self, input_size=(32,32,3)):\n",
    "    input_image = keras.layers.Input(input_size)\n",
    "    input_mask = keras.layers.Input(input_size, name='encoder_input')\n",
    "  \n",
    "    conv1, mask1, conv2, mask2 = self.__encoder_layer(32, input_image, input_mask, ['conv1', 'conv2'])\n",
    "    conv3, mask3, conv4, mask4 = self.__encoder_layer(64, conv2, mask2, ['conv3', 'conv4'])\n",
    "    conv5, mask5, conv6, mask6 = self.__encoder_layer(128, conv4, mask4, ['conv5', 'conv6'])\n",
    "    conv7, mask7, conv8, mask8 = self.__encoder_layer(256, conv6, mask6, ['conv7', 'encoder_output'])\n",
    "\n",
    "    conv9, mask9, conv10, mask10 = self.__decoder_layer(256, 128, conv8, mask8, conv7, mask7, ['conv9', 'conv10'])\n",
    "    conv11, mask11, conv12, mask12 = self.__decoder_layer(128, 64, conv10, mask10, conv5, mask5, ['conv11', 'conv12'])\n",
    "    conv13, mask13, conv14, mask14 = self.__decoder_layer(64, 32, conv12, mask12, conv3, mask3, ['conv13', 'conv14'])\n",
    "    conv15, mask15, conv16, mask16 = self.__decoder_layer(32, 3, conv14, mask14, conv1, mask1, ['conv15', 'decoder_output'])\n",
    "\n",
    "    outputs = keras.layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv16)\n",
    "\n",
    "    return keras.models.Model(inputs=[input_image, input_mask], outputs=[outputs])\n",
    "    \n",
    "  def __encoder_layer(self, filters, in_layer, in_mask, names):\n",
    "    conv1, mask1 = PConv2D(32, (3,3), strides=1, padding='same', name=names[0])([in_layer, in_mask])\n",
    "    conv1 = keras.activations.relu(conv1)\n",
    "\n",
    "    conv2, mask2 = PConv2D(32, (3,3), strides=2, padding='same', name=names[1])([conv1, mask1])\n",
    "    # conv2 = keras.layers.BatchNormalization()(conv2, training=True)\n",
    "    conv2 = keras.activations.relu(conv2)\n",
    "\n",
    "    return conv1, mask1, conv2, mask2\n",
    "\n",
    "  def __decoder_layer(self, filter1, filter2, in_img, in_mask, share_img, share_mask, names):\n",
    "    up_img = keras.layers.UpSampling2D(size=(2,2))(in_img)\n",
    "    up_mask = keras.layers.UpSampling2D(size=(2,2))(in_mask)\n",
    "    concat_img = keras.layers.Concatenate(axis=3)([share_img, up_img])\n",
    "    concat_mask = keras.layers.Concatenate(axis=3)([share_mask, up_mask])\n",
    "\n",
    "    conv1, mask1 = PConv2D(filter1, (3,3), padding='same', name=names[0])([concat_img, concat_mask])\n",
    "    conv1 = keras.activations.relu(conv1)\n",
    "\n",
    "    conv2, mask2 = PConv2D(filter2, (3,3), padding='same', name=names[1])([conv1, mask1])\n",
    "    # conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    conv2 = keras.activations.relu(conv2)\n",
    "\n",
    "    return conv1, mask1, conv2, mask2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:12:23.112239Z",
     "iopub.status.busy": "2022-05-06T06:12:23.111658Z",
     "iopub.status.idle": "2022-05-06T06:14:30.309800Z",
     "shell.execute_reply": "2022-05-06T06:14:30.308675Z",
     "shell.execute_reply.started": "2022-05-06T06:12:23.112192Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = InpaintingModel_2().prepare_model()\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=[dice_coef])\n",
    "keras.utils.plot_model(model, show_shapes=True, dpi=60, to_file='model_v2.png')\n",
    "\n",
    "wandb.init(entity='kv1388', project=\"image-impainting-pconv-sgd-mse\")\n",
    "\n",
    "class PredictionLogger(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(PredictionLogger, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, logs, epoch):\n",
    "        sample_idx = 54\n",
    "        [masked_images, masks], sample_labels = testgen[sample_idx]  \n",
    "        \n",
    "        m_images = []\n",
    "        binary_masks = []\n",
    "        predictions = []\n",
    "        labels = []\n",
    "        \n",
    "        for i in range(32):\n",
    "          inputs = [masked_images[i].reshape((1,)+masked_images[i].shape), masks[i].reshape((1,)+masks[i].shape)]\n",
    "          impainted_image = model.predict(inputs)\n",
    "\n",
    "          m_images.append(masked_images[i])\n",
    "          binary_masks.append(masks[i])\n",
    "          predictions.append(impainted_image.reshape(impainted_image.shape[1:]))\n",
    "          labels.append(sample_labels[i])\n",
    "\n",
    "        wandb.log({\"masked_images\": [wandb.Image(m_image)\n",
    "                              for m_image in m_images]})\n",
    "        wandb.log({\"masks\": [wandb.Image(mask)\n",
    "                              for mask in binary_masks]})\n",
    "        wandb.log({\"predictions\": [wandb.Image(inpainted_image)\n",
    "                              for inpainted_image in predictions]})\n",
    "        wandb.log({\"labels\": [wandb.Image(label)\n",
    "                              for label in labels]})\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T06:14:30.312772Z",
     "iopub.status.busy": "2022-05-06T06:14:30.311625Z",
     "iopub.status.idle": "2022-05-06T07:09:03.760822Z",
     "shell.execute_reply": "2022-05-06T07:09:03.759025Z",
     "shell.execute_reply.started": "2022-05-06T06:14:30.312718Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = model.fit_generator(traingen, validation_data=testgen, \n",
    "          epochs=50, \n",
    "          steps_per_epoch=len(traingen), \n",
    "          validation_steps=len(testgen),\n",
    "          use_multiprocessing=True,\n",
    "          callbacks=[WandbCallback(),\n",
    "                     PredictionLogger()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:09:03.771112Z",
     "iopub.status.busy": "2022-05-06T07:09:03.767477Z",
     "iopub.status.idle": "2022-05-06T07:09:18.175992Z",
     "shell.execute_reply": "2022-05-06T07:09:18.174333Z",
     "shell.execute_reply.started": "2022-05-06T07:09:03.771016Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('./encoder_decoder_pconv_sgd_50epochs_512batch-mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:09:18.190524Z",
     "iopub.status.busy": "2022-05-06T07:09:18.189900Z",
     "iopub.status.idle": "2022-05-06T07:10:05.141334Z",
     "shell.execute_reply": "2022-05-06T07:10:05.139198Z",
     "shell.execute_reply.started": "2022-05-06T07:09:18.190451Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = 20\n",
    "sample_idx = 54\n",
    "[masked_images, masks], sample_labels = traingen[sample_idx]\n",
    "\n",
    "fig, axs = plt.subplots(nrows=rows, ncols=4, figsize=(8, 2*rows))\n",
    "\n",
    "for i in range(20):\n",
    "    inputs = [masked_images[i].reshape((1,)+masked_images[i].shape), masks[i].reshape((1,)+masks[i].shape)]\n",
    "    impainted_image = model.predict(inputs)\n",
    "    axs[i][0].imshow(masked_images[i])\n",
    "    axs[i][1].imshow(masks[i])\n",
    "    axs[i][2].imshow(impainted_image.reshape(impainted_image.shape[1:]))\n",
    "    axs[i][3].imshow(sample_labels[i])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "ssim_test=[]\n",
    "\n",
    "for i in range(len(sample_labels)):\n",
    "    inputs = [masked_images[i].reshape((1,)+masked_images[i].shape), masks[i].reshape((1,)+masks[i].shape)]\n",
    "    impainted_image = model.predict(inputs)\n",
    "    ssim_test.append(ssim(sample_labels[i],impainted_image[0],channel_axis=2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:10:05.144694Z",
     "iopub.status.busy": "2022-05-06T07:10:05.143979Z",
     "iopub.status.idle": "2022-05-06T07:10:05.155404Z",
     "shell.execute_reply": "2022-05-06T07:10:05.154176Z",
     "shell.execute_reply.started": "2022-05-06T07:10:05.144648Z"
    }
   },
   "outputs": [],
   "source": [
    "max(ssim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-06T07:10:05.159889Z",
     "iopub.status.busy": "2022-05-06T07:10:05.158926Z",
     "iopub.status.idle": "2022-05-06T07:10:05.176599Z",
     "shell.execute_reply": "2022-05-06T07:10:05.174856Z",
     "shell.execute_reply.started": "2022-05-06T07:10:05.159842Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "sum(ssim_test)/len(ssim_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
